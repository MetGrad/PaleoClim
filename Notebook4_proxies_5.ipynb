{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #4: The proxy database\n",
    "\n",
    "In this script, we'll take a look at one of the LMR inputs: the proxy database.\n",
    "\n",
    "One of the initial steps of running the LMR is to preprocess the proxy network.  This step puts the data into a standard format and calculates annual-mean values, among other things.  Let's take a look at these standard files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A non-python command to make sure all figures are plotted on this page.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 94, lon: 192, time: 1968, nbnds: 2)\n",
      "Coordinates:\n",
      "  * lat        (lat) float32 88.54 86.65 84.75 82.85 ... -84.75 -86.65 -88.54\n",
      "  * lon        (lon) float32 0.0 1.875 3.75 5.625 ... 352.5 354.4 356.2 358.1\n",
      "  * time       (time) datetime64[ns] 1851-01-01 1851-02-01 ... 2014-12-01\n",
      "Dimensions without coordinates: nbnds\n",
      "Data variables:\n",
      "    time_bnds  (time, nbnds) float64 ...\n",
      "    air        (time, lat, lon) float32 ...\n",
      "Attributes: (12/19)\n",
      "    Conventions:             CF-1.2\n",
      "    title:                   4x Daily NOAA-CIRES 20th Century Reanalysis V2c\n",
      "    platform:                Model\n",
      "    institution:             NOAA ESRL Physical Sciences Division & CU/CIRES ...\n",
      "    version:                 2c\n",
      "    history:                 created 2015/02 by Hoop (chunked, deflated non-p...\n",
      "    ...                      ...\n",
      "    comments:                Data is from \\nNOAA-CIRES 20th Century Reanalysi...\n",
      "    forcing:                 CO2, Sl, Vl, SST, 0z (0z is prognostic, SST is S...\n",
      "    dataset_title:           NOAA-CIRES 20th Century Reanalysis (V2c)\n",
      "    References:              https://www.esrl.noaa.gov/psd/data/gridded/data....\n",
      "    forcing_note:            Additional information on the external forcings ...\n",
      "    citation:                Compo,G.P. <https://www.esrl.noaa.gov/psd/people...\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary python packages \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "\n",
    "dataSet = xr.open_dataset('airtemp.sfc.mon.mean_noaa20cr.nc')\n",
    "print(dataSet)\n",
    "\n",
    "from load_gridded_data import read_gridded_data_NOAA20CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the proxy data and metadata using the pandas library.\n",
    "proxies = pd.read_pickle('../LMR_data/data/proxies/Pages2kv1_Proxies.df.pckl')\n",
    "metadata = pd.read_pickle('../LMR_data/data/proxies/Pages2kv1_Metadata.df.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(2512, 577)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The \"type\" and \"shape\" commands can be used to learn more about the data set.\n",
    "# The proxy data:\n",
    "print(type(proxies))\n",
    "print(proxies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(522, 15)\n"
     ]
    }
   ],
   "source": [
    "# The proxy metadata:\n",
    "print(type(metadata))\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ant_01   Ant_02 Ant_03 Ant_04 Ant_05 Ant_06 Ant_07 Ant_08 Ant_09  \\\n",
      "Year C.E.                                                                    \n",
      "-500         NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-499         NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-498         NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-497         NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-496         NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "...          ...      ...    ...    ...    ...    ...    ...    ...    ...   \n",
      " 2007        NaN -21.6681    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2008        NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2009        NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2010        NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2011        NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "          Ant_10  ... SAm_14  SAm_15 SAm_16 SAm_17 SAm_18 SAm_19 SAm_20  \\\n",
      "Year C.E.         ...                                                     \n",
      "-500         NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-499         NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-498         NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-497         NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "-496         NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "...          ...  ...    ...     ...    ...    ...    ...    ...    ...   \n",
      " 2007     -158.1  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2008        NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2009        NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2010        NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      " 2011        NaN  ...    NaN     NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "          SAm_21 SAm_22 SAm_23  \n",
      "Year C.E.                       \n",
      "-500         NaN    NaN    NaN  \n",
      "-499         NaN    NaN    NaN  \n",
      "-498         NaN    NaN    NaN  \n",
      "-497         NaN    NaN    NaN  \n",
      "-496         NaN    NaN    NaN  \n",
      "...          ...    ...    ...  \n",
      " 2007        NaN    NaN    NaN  \n",
      " 2008        NaN    NaN    NaN  \n",
      " 2009        NaN    NaN    NaN  \n",
      " 2010        NaN    NaN    NaN  \n",
      " 2011        NaN    NaN    NaN  \n",
      "\n",
      "[2512 rows x 577 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the contents of the proxy file.\n",
    "print(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ant_01', 'Ant_02', 'Ant_03', 'Ant_04', 'Ant_05', 'Ant_06', 'Ant_07',\n",
      "       'Ant_08', 'Ant_09', 'Ant_10',\n",
      "       ...\n",
      "       'SAm_14', 'SAm_15', 'SAm_16', 'SAm_17', 'SAm_18', 'SAm_19', 'SAm_20',\n",
      "       'SAm_21', 'SAm_22', 'SAm_23'],\n",
      "      dtype='object', length=577)\n"
     ]
    }
   ],
   "source": [
    "# The \"keys\" command shows all of the keys for this dataset.\n",
    "print(proxies.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PAGES 2k Region', 'Proxy ID', 'Country/Region', 'Area', 'Site',\n",
      "       'Lat (N)', 'Lon (E)', 'Archive type', 'Proxy measurement',\n",
      "       'Proxy other info', 'Sign relation to temp', 'Oldest (C.E.)',\n",
      "       'Youngest (C.E.)', 'Resolution (yr)', 'Reference'],\n",
      "      dtype='object')\n",
      "0      positive\n",
      "1      positive\n",
      "2      positive\n",
      "3      positive\n",
      "4      positive\n",
      "         ...   \n",
      "517    Negative\n",
      "518    Positive\n",
      "519    Positive\n",
      "520    Positive\n",
      "521    Positive\n",
      "Name: Sign relation to temp, Length: 522, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display all of the fields in the metadata file.\n",
    "print(metadata.keys())\n",
    "print(metadata['Sign relation to temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PAGES 2k Region :                 Asia\n",
      "                   Proxy ID :              Asi_020\n",
      "             Country/Region : Altai Mountains (AT)\n",
      "                       Area :              RUSS139\n",
      "                       Site :               UKHLWW\n",
      "                    Lat (N) :                50.15\n",
      "                    Lon (E) :     85.3666666666667\n",
      "               Archive type :            Tree ring\n",
      "          Proxy measurement :       Latewood width\n",
      "           Proxy other info :                  nan\n",
      "      Sign relation to temp :             Positive\n",
      "              Oldest (C.E.) :               1581.0\n",
      "            Youngest (C.E.) :               1994.0\n",
      "            Resolution (yr) :                  1.0\n",
      "                  Reference :    Schweingruber, FH\n"
     ]
    }
   ],
   "source": [
    "# As an example, plot the metadata of the first record.\n",
    "# Loop through every element of the metadata and print it to screen.\n",
    "for key in metadata.keys():\n",
    "    print('%27s : %20s' % (key, metadata.loc[100][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-10-eccc0063637a>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-eccc0063637a>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    if search_string.lower() in metadata.loc[i][field_to_search].lower():\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# We can write some code to search the metadata for a proxy we're interested in.\n",
    "\n",
    "search_string = 'South'\n",
    "field_to_search = 'PAGES 2k Region'\n",
    "\n",
    "search_string2 = 'Tree ring'\n",
    "field_to_search2 = 'Archive type'\n",
    "\n",
    "# Loop through every key.  If part of the key matches the the search string, print the index and the key.\n",
    "\n",
    "n_proxies = metadata.shape[0]\n",
    "print('%5s: %20s: %20s: %20s:' % ('index','Site','Country/Region','Archive type'))\n",
    "\n",
    "Asia_index = []\n",
    "count = 0\n",
    "\n",
    "#calibration to modern observation part of record \n",
    "#proxies = proxies.truncate(before=1850, after=2000, axis=\"index\")\n",
    "\n",
    "for i in range(n_proxies):\n",
    "    if isinstance(metadata.loc[i][field_to_search], str):\n",
    "        if search_string.lower() in metadata.loc[i][field_to_search].lower() and search_string2.lower() in metadata.loc[i][field_to_search2].lower():\n",
    "        if search_string.lower() in metadata.loc[i][field_to_search].lower():\n",
    "            print('%5s: %20s, %20s, %20s' % (i, metadata.loc[i]['Site'], metadata.loc[i]['Country/Region'],\\\n",
    "                                              metadata.loc[i]['Archive type']))\n",
    "            \n",
    "            count = count+1\n",
    "            Asia_index = np.append(Asia_index, i)\n",
    "print(Asia_index)\n",
    "\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the index of a record you're interested in.\n",
    "index_selected = Asia_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through every element of the metadata and print it to screen.\n",
    "for key in metadata.keys():\n",
    "    print('%27s : %20s' % (key, metadata.loc[index_selected][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the key of the desired record.\n",
    "proxyID_selected = metadata.loc[index_selected]['Proxy ID']\n",
    "print(proxyID_selected)\n",
    "\n",
    "# Get the data for this record.\n",
    "proxy_data = proxies[proxyID_selected]\n",
    "print(proxy_data.shape)\n",
    "#standardize\n",
    "proxy_data_standardize = (proxy_data-proxy_data.mean())/proxy_data.std()\n",
    "print(proxy_data_standardize.shape)\n",
    "proxy_data_composite = proxy_data_standardize.mean(axis=1)\n",
    "print(proxy_data_composite.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat_ix = np.argmin(abs(obs_lat - min_lat))\n",
    "max_lat_ix = np.argmin(abs(obs_lat - max_lat))\n",
    "\n",
    "min_lon_ix = np.argmin(abs(obs_lon - min_lon))\n",
    "max_lon_ix = np.argmin(abs(obs_lon - max_lon))\n",
    "\n",
    "min_tim_ix = np.argmin(abs(obs_time - start_yr))\n",
    "max_tim_ix = np.argmin(abs(obs_time - end_yr))\n",
    "\n",
    "obs_time = obs_time[min_tim_ix:max_tim_ix+1]\n",
    "obs_select = obs_temp[min_tim_ix:max_tim_ix,max_lat_ix:min_lat_ix+1, min_lon_ix:max_lon_ix+1]  # add 1 to the max lat to make it inclusive\n",
    "obs_anomaly = obs_select - np.mean(obs_select,axis=0)     # convert to anomaly (NOAA data is absolute temp in units of Kelvin)\n",
    "        \n",
    "print(obs_anomaly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a figure of the proxy record.\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = plt.axes([.1,.1,.8,.8])\n",
    "plt.plot(proxy_data_composite,color='k',marker='o',linewidth=1)\n",
    "#plt.title(str(site_name)+\" (\"+str(archive_type)+\").  Lat: \"+str(lat)+\"$^\\circ$N, Lon: \"+\\\n",
    "          #str(lon)+\"$^\\circ$E\\nReference: \"+reference[0:100])\n",
    "#plt.title(\"Composite of Asia Tree Ring Records\")\n",
    "plt.title(\"Proxy Composite v. Observational Temp\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xlim(1850,2000)\n",
    "#plt.ylabel(\"Standard Deviation\")\n",
    "plt.ylabel('deg C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration\n",
    "\n",
    "Search for a different record and look at the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Use of data from both proxy records and climate models is crucial to the advancement of paleoclimate research.\n",
    "* How many of you primarily work with proxy records?\n",
    "* How many of you primarily work with model output?\n",
    "* Do you often use data from both areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bunch of PAGES2k style settings\n",
    "class PAGES2k(object):\n",
    "    archive_types = ['Bivalve',\n",
    "                    'Borehole',\n",
    "                    'Coral',\n",
    "                    'Documentary',\n",
    "                    'Ice core',\n",
    "                    'Hybrid',\n",
    "                    'Lake/wetland sediments',\n",
    "                    'Lake sediment',\n",
    "                    'Marine sediment',\n",
    "                    'Marine sediments',\n",
    "                    'Sclerosponge',\n",
    "                    'Speleothem',\n",
    "                    'Tree ring',\n",
    "                    'Historic',\n",
    "                    'Instrumental',\n",
    "                    'Hyrax midden']\n",
    "    markers = ['p', 'p', 'o', 'v', 'd', '*', 's', 's', '8','8', 'D', '^','h','1','2','3']\n",
    "    markers_dict = dict(zip(archive_types, markers))\n",
    "    \n",
    "    colors = [np.array([ 1.        ,  0.83984375,  0.        ]),\n",
    "              np.array([ 0.73828125,  0.71484375,  0.41796875]),\n",
    "              np.array([ 1.        ,  0.546875  ,  0.        ]),\n",
    "              np.array([ 0.41015625,  0.41015625,  0.41015625]),\n",
    "              np.array([ 0.52734375,  0.8046875 ,  0.97916667]),\n",
    "              np.array([ 0.        ,  0.74609375,  1.        ]),\n",
    "              np.array([ 0.25390625,  0.41015625,  0.87890625]),\n",
    "              np.array([ 0.25390625,  0.41015625,  0.87890625]),\n",
    "              np.array([ 0.54296875,  0.26953125,  0.07421875]),\n",
    "              np.array([ 0.54296875,  0.26953125,  0.07421875]),\n",
    "              np.array([ 1         ,           0,           0]),\n",
    "              np.array([ 1.        ,  0.078125  ,  0.57421875]),\n",
    "              np.array([ 0.1953125 ,  0.80078125,  0.1953125 ]),\n",
    "              np.array([ 0.1953125 ,  0.80078125,  0.8 ]),\n",
    "              np.array([ 0.2 ,  0.2,  0.8 ]),\n",
    "              np.array([ 0.8 ,  0.80078125,  0.8 ])]\n",
    "    colors_dict = dict(zip(archive_types, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sites(df, title=None, lon_col='Lon (E)', lat_col='Lat (N)', archiveType_col='Archive type',\n",
    "               title_size=20, title_weight='bold', figsize=[10, 8], projection=ccrs.Robinson(), markersize=50,\n",
    "               plot_legend=True, legend_ncol=3, legend_anchor=(0, -0.4), legend_fontsize=15, frameon=False, ax=None):\n",
    "    \n",
    "    ''' Plot the location of the sites on a map\n",
    "\n",
    "    Args:\n",
    "        df (Pandas DataFrame): the Pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        ax (Axes): the map plot of the sites\n",
    "\n",
    "    '''\n",
    "    p = PAGES2k()\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = plt.subplot(projection=projection)\n",
    "\n",
    "    sns.set(style=\"ticks\", font_scale=2)\n",
    "\n",
    "    # plot map\n",
    "    if title:\n",
    "        plt.title(title, fontsize=title_size, fontweight=title_weight)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.LAND, facecolor='gray', alpha=0.3)\n",
    "    ax.gridlines(edgecolor='gray', linestyle=':')\n",
    "\n",
    "    # plot markers by archive types\n",
    "    s_plots = []\n",
    "    type_names = []\n",
    "    df_archiveType_set = np.unique(df[archiveType_col])\n",
    "    for type_name in df_archiveType_set:\n",
    "        selector = df[archiveType_col] == type_name\n",
    "        type_names.append(f'{type_name} (n={len(df[selector])})')\n",
    "        s_plots.append(\n",
    "            ax.scatter(\n",
    "                df[selector][lon_col], df[selector][lat_col], marker=p.markers_dict[type_name],\n",
    "                c=p.colors_dict[type_name], edgecolor='k', s=markersize, transform=ccrs.PlateCarree()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # plot legend\n",
    "    if plot_legend:\n",
    "        plt.legend(\n",
    "            s_plots, type_names,\n",
    "            scatterpoints=1,\n",
    "            bbox_to_anchor=legend_anchor,\n",
    "            loc='lower left',\n",
    "            ncol=legend_ncol,\n",
    "            frameon=frameon,\n",
    "            fontsize=legend_fontsize\n",
    "        )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot map of proxy data\n",
    "ax = plot_sites(metadata, title=f'PAGES2k Network (n={len(metadata)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
